{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "40ec7379",
      "metadata": {
        "id": "40ec7379"
      },
      "source": [
        "# Data Cleaning & Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hCzeR4yzotVL",
      "metadata": {
        "id": "hCzeR4yzotVL"
      },
      "source": [
        "This tutorial will walk you through the steps of data cleaning and preprocessing using a dataset of Airbnb listings in NYC from 2019.\n",
        "\n",
        "Big thanks to Sumon Singh who created this tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48799f16",
      "metadata": {
        "id": "48799f16"
      },
      "source": [
        "## Load Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yUE9XCOCovq2",
      "metadata": {
        "id": "yUE9XCOCovq2"
      },
      "source": [
        "First, import necessary libraries such as:\n",
        "\n",
        "NumPy: for numerical operations.\n",
        "Pandas: for data manipulation and analysis.\n",
        "Scikit-learn: for machine learning tasks, including preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "59ba2bc1",
      "metadata": {
        "id": "59ba2bc1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1c20e2f",
      "metadata": {
        "id": "e1c20e2f"
      },
      "source": [
        "## Load The Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cQGVEKWnoyCW",
      "metadata": {
        "id": "cQGVEKWnoyCW"
      },
      "source": [
        "Load the Airbnb dataset into a pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "19ece5b2",
      "metadata": {
        "id": "19ece5b2"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/sumony2j/Data_Cleaning_Preprocessing/refs/heads/main/AB_NYC_2019.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9AfsioCro2rA",
      "metadata": {
        "id": "9AfsioCro2rA"
      },
      "source": [
        "Explore the dataset by looking at the first few rows, shape, and information about the columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98b9e219",
      "metadata": {
        "id": "98b9e219",
        "outputId": "3af0f6c3-072f-434c-9284-23260503182a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "022dd180",
      "metadata": {
        "id": "022dd180",
        "outputId": "1a30374a-0a8e-4ba1-e060-bb0c72ceb91f"
      },
      "outputs": [],
      "source": [
        "# Show the shpe of the dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66e5cde8",
      "metadata": {
        "id": "66e5cde8",
        "outputId": "354ef142-9b90-4ee5-944b-debf83f88bd0"
      },
      "outputs": [],
      "source": [
        "# have you tried to use .info()?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b16f79e",
      "metadata": {
        "id": "5b16f79e"
      },
      "source": [
        "## Check null values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fgJZTFm8o6mU",
      "metadata": {
        "id": "fgJZTFm8o6mU"
      },
      "source": [
        "Check for missing values in each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aace7fc5",
      "metadata": {
        "id": "aace7fc5",
        "outputId": "6987ba4f-75b6-4007-c748-de45215f5612"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2473a7c5",
      "metadata": {
        "id": "2473a7c5"
      },
      "source": [
        "## Drop unnecessary columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ZiXYe3jo9YW",
      "metadata": {
        "id": "9ZiXYe3jo9YW"
      },
      "source": [
        "Remove columns that are not relevant to the analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e636ab0",
      "metadata": {
        "id": "0e636ab0"
      },
      "outputs": [],
      "source": [
        "unnecessary_cols = ['name','host_name','id','host_id','last_review']\n",
        "# remove columns that are not necessary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f5865ac",
      "metadata": {
        "id": "6f5865ac"
      },
      "source": [
        "## Fill missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4TWnPUtdo_vd",
      "metadata": {
        "id": "4TWnPUtdo_vd"
      },
      "source": [
        "Fill missing values in the 'reviews_per_month' column using the most frequent value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9cbcffc",
      "metadata": {
        "id": "b9cbcffc"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1efd8c6",
      "metadata": {
        "id": "d1efd8c6"
      },
      "outputs": [],
      "source": [
        "df[['reviews_per_month']]=imputer.fit_transform(df[['reviews_per_month']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "110c7920",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['price'].min()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75efaa3b",
      "metadata": {},
      "source": [
        "# Data Preprocessing: Scaling and Transforming Skewed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "788270d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# print the range of the price column\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8564fbea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# print the range of the reviews_per_month column"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e5d6de3",
      "metadata": {},
      "source": [
        "## Why scale data?\n",
        "\n",
        "Many machine learning models (e.g. linear regression, k-means, PCA) assume that all features contribute equally to the distance or error function.  \n",
        "\n",
        "However, when variables are on **different ranges**:\n",
        "- Large-scale features dominate optimization.\n",
        "- Gradient descent converges slowly or gets stuck.\n",
        "- Coefficients in regression become hard to interpret.\n",
        "\n",
        "We need a way to bring all variables to a comparable scale **without distorting relationships**.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c317a896",
      "metadata": {},
      "source": [
        "## Range transformations with pandas\n",
        "\n",
        "Two simple transformations we can do are **Min-Max** and **Z-score** scaling. Let's compute these manually.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ae2a271",
      "metadata": {},
      "outputs": [],
      "source": [
        "# use .describe() to have a look at the price and reviews_per_month columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca6738f9",
      "metadata": {},
      "source": [
        "### Min-max scaling\n",
        "\n",
        "Compute a Min-Max normalized version of both columns. \n",
        "Min-Max scaling transforms features to a fixed range, usually [0, 1]. The formula is:\n",
        "$$ x_{scaled} = \\frac{x - X_{min}}{X_{max} - X_{min}} $$\n",
        "\n",
        "Where x is the original value, X_min is the minimum value of the feature, and X_max is the maximum value of the feature.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25f26667",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Min-Max\n",
        "df['price_minmax'] = (df['price'] - df['price'].min()) / (df['price'].max() - df['price'].min())\n",
        "df['reviews_minmax'] = (df['reviews_per_month'] - df['reviews_per_month'].min()) / (df['reviews_per_month'].max() - df['reviews_per_month'].min())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4617f29a",
      "metadata": {},
      "source": [
        "Now, let's look at z-scores. A z-score is defined as: \n",
        "$$ z = \\frac{x - \\mu}{\\sigma} $$\n",
        "\n",
        "where x is the original value, μ is the mean of the feature, and σ is the standard deviation of the feature.\n",
        "\n",
        "You can interpret a z-score as the number of standard deviations a value is from the mean. It measures the distance of a data point from the mean in units of standard deviations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36e721ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Z-score\n",
        "df['price_z'] = (df['price'] - df['price'].mean()) / df['price'].std()\n",
        "df['reviews_z'] = (df['reviews_per_month'] - df['reviews_per_month'].mean()) / df['reviews_per_month'].std()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dea65b53",
      "metadata": {},
      "source": [
        "### ✏️ Your turn\n",
        "> Run the code above to compute the min-max and z-score normalized version of both columns. Then:\n",
        "> - **Check:** If the transformations were successful, the new columns should have ranges roughly [0, 1] (Min-Max) or mean ≈ 0, std ≈ 1 (Z-score).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15ea075b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "304e3608",
      "metadata": {},
      "source": [
        "## Using Scikit-learn scalers\n",
        "\n",
        "We can replicate the same transformations using the widely popular `scikit-learn` library for machine learning. `scikit-learn` provides consistent tools for scaling as part of preprocessing pipelines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74ef24e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Define a scaler\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "# fit parameters to data, then transform it\n",
        "scaled_minmax = scaler_minmax.fit_transform(df[['price', 'reviews_per_month']])\n",
        "\n",
        "# add the scaled columns to the dataframe\n",
        "df[['price_mm', 'reviews_mm']] = scaled_minmax\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc0c4545",
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler_standard = StandardScaler()\n",
        "scaled_standard = scaler_standard.fit_transform(df[['price', 'reviews_per_month']])\n",
        "df[['price_std', 'reviews_std']] = scaled_standard"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cabc63cf",
      "metadata": {},
      "source": [
        "### ✏️ Your turn: transform the data using one of the methods above.\n",
        "> - import the necessary libraries\n",
        "> - Load the data \n",
        "> - transform the price and reviews_per_month columns using a `RobustScaler()`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90799349",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import the necessary libraries\n",
        "...\n",
        "\n",
        "# Load the data \n",
        "...\n",
        "\n",
        "# transform the price and reviews_per_month columns using Min-Max and Z-score normalization. Pick the method you prefer.\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "90936a4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare values in the ['price_minmax','price_mm','price_z','price_std'] columns\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f89ec7d8",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Visualising distributions\n",
        "It is difficult to understand variables (and their transformations) just by printing their values. A better approach is to visualise the distribution of values. This allows to visually inspect the distributions and their transformations.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dfea16f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
        "# sns.histplot(df['price'], bins=50, ax=axes[0], color='tomato')\n",
        "# sns.histplot(df['reviews_per_month'], bins=50, ax=axes[1], color='steelblue')\n",
        "# axes[0].set_title('Price Distribution')\n",
        "# axes[1].set_title('Reviews per Month Distribution')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cc18432",
      "metadata": {},
      "source": [
        "Visualising the distributions showed us something that we could have not guessed by simply looking a the dataframe outputs, namely the data of these two variables is highly skewed. Skewed data can bias statistical models. \n",
        "\n",
        "We can compute the skewness of a distribution by using the `skew()` function in pandas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1030834",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[['price', 'reviews_per_month']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b087247",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Why skewness can be problematic\n",
        "\n",
        "In **linear regression**, **logistic regression**, and **PCA**, we often assume variables are *approximately normal*:\n",
        "\n",
        "* Highly skewed variables can create *non-linear residuals* and *non-constant variance*.\n",
        "* They can reduce predictive performance or interpretability.\n",
        "* They make distance-based metrics unreliable (e.g. k-means centroids get pulled toward long tails).\n",
        "\n",
        "**Goal:** We want to transform the data to reduce skewness and make the distribution closer to Gaussian.\n",
        "\n",
        "\n",
        "### Common transformations\n",
        "\n",
        "| Method                      | Description                                   | When to use                   |\n",
        "| --------------------------- | --------------------------------------------- | ----------------------------- |\n",
        "| **Logarithmic**             | `log(x + 1)`                                  | Positive, right-skewed data   |\n",
        "| **Square root / cube root** | `sqrt(x)` or `x**(1/3)`                       | Count data, moderate skew     |\n",
        "| **Box-Cox**                 | Power transform for strictly positive data    | Positive data only            |\n",
        "| **Yeo-Johnson**             | Box-Cox variant that works with negatives     | Any real values               |\n",
        "| **Quantile transform**      | Maps data to a uniform or normal distribution | Extreme skew or multimodality |\n",
        "\n",
        "---\n",
        "\n",
        "## Applying Quantile, Box-Cox, and Yeo-Johnson (using scikit-learn)\n",
        "\n",
        "Let’s explore how these methods reshape distributions.\n",
        "We’ll use synthetic data to illustrate the effects (based on the official scikit-learn example).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4073600",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PowerTransformer, QuantileTransformer\n",
        "\n",
        "# Box-Cox (only works if all values > 0)\n",
        "bc = PowerTransformer(method='box-cox')\n",
        "df['price_boxcox'] = bc.fit_transform(df[['price']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac342a38",
      "metadata": {},
      "source": [
        "Let's visualise the results of the Box-Cox transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "427dab1f",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1f9bec53",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Yeo-Johnson\n",
        "yj = PowerTransformer(method='yeo-johnson')\n",
        "df['reviews_yj'] = yj.fit_transform(df[['reviews_per_month']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05007b69",
      "metadata": {},
      "source": [
        "Let's visualise the results of the Jeo-Johnson transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15da9d19",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "54e9c61d",
      "metadata": {},
      "source": [
        "Let's visualise the Box-Cox and Yeo-Johnson transformations side by side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f3b5e4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
        "sns.histplot(df['price_boxcox'], bins=50, ax=axes[0], color='darkorange')\n",
        "sns.histplot(df['reviews_yj'], bins=50, ax=axes[1], color='teal')\n",
        "axes[0].set_title('Price after Box-Cox')\n",
        "axes[1].set_title('Reviews per Month after Yeo-Johnson')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddeead3d",
      "metadata": {},
      "source": [
        "### ✏️ Your turn: Quantile transformation\n",
        "> A last transform that we can use is the Quantile transformation. This transfrormation maps the data to a uniform or normal distribution, using the rank of the data rather than its actual value. Apply a Quantile transformation to the price or the reviews column and visualise the results. In scikit learn the `QuantileTransformer` class can be used for this purpose.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59a327c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quantile transform to normal\n",
        "qt = QuantileTransformer(output_distribution='uniform', random_state=42)\n",
        "df['price_qt'] = qt.fit_transform(df[['price']])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0037ce1",
      "metadata": {},
      "source": [
        "Let's visualise the results of the Quantile transformation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7265ce1e",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5ae7b63f",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "| Problem                       | Transformation                      | Library                                                         |\n",
        "| ----------------------------- | ----------------------------------- | --------------------------------------------------------------- |\n",
        "| Variables on different scales | Min-Max / Standardization           | `pandas`, `sklearn.preprocessing`                               |\n",
        "| Highly skewed distributions   | Log, Box-Cox, Yeo-Johnson, Quantile | `sklearn.preprocessing.PowerTransformer`, `QuantileTransformer` |\n",
        "\n",
        "---\n",
        "\n",
        "### Key takeaways\n",
        "\n",
        "* Scaling makes features comparable and stabilises model training.\n",
        "* Skewness can break assumptions of linear models.\n",
        "* Power and quantile transformations can make data more Gaussian.\n",
        "* Always visualise before and after transforming!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f30bbe6f",
      "metadata": {
        "id": "f30bbe6f"
      },
      "source": [
        "# Encode catagorical variables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PX3NPU9XpCOE",
      "metadata": {
        "id": "PX3NPU9XpCOE"
      },
      "source": [
        "Categorical variables are non-numeric variables that represent discrete categories or groups. Examples include sex, color, brand, city, etc. To be used in machine learning models, these categorical variables need to be converted into a numerical format. This process is called encoding.\n",
        "\n",
        "First we need to identify categorical columns. \n",
        "\n",
        "Hint: if the column (or Series) is made of strings, Pandas will assign the 'dtype' method the string 'object'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "65ea6ee3",
      "metadata": {
        "id": "65ea6ee3"
      },
      "outputs": [],
      "source": [
        "# create a list comprehension or a for loop across df columns to get the columns with dtype='object'\n",
        "l = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c675081b",
      "metadata": {
        "id": "c675081b",
        "outputId": "b982e0c4-ac7c-4e2d-bfb8-bdbc00e1e88e"
      },
      "outputs": [],
      "source": [
        "l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LPSbfBgTpFme",
      "metadata": {
        "id": "LPSbfBgTpFme"
      },
      "source": [
        "Check the number of unique values in each categorical column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "41bb029d",
      "metadata": {
        "id": "41bb029d",
        "outputId": "519ce8f2-81f3-4a1e-fdc0-d5698826ced4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique values : \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('Number of unique values : ')\n",
        "# your code here\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e646152f",
      "metadata": {
        "id": "e646152f",
        "outputId": "8fe9bfd2-d941-409e-84d1-bce82c1dd53f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Private room', 'Entire home/apt', 'Shared room'], dtype=object)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['room_type'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "311afded",
      "metadata": {
        "id": "311afded"
      },
      "source": [
        "## Convert room_type into numeric data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98JIwVCtpIOJ",
      "metadata": {
        "id": "98JIwVCtpIOJ"
      },
      "source": [
        "Convert the 'room_type' column into numerical data using ordinal encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "23f2d6fc",
      "metadata": {
        "id": "23f2d6fc"
      },
      "outputs": [],
      "source": [
        "room_type=df['room_type'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "312d0f50",
      "metadata": {
        "id": "312d0f50"
      },
      "outputs": [],
      "source": [
        "# convert the room type column into a numpy array\n",
        "room_type=np.array(room_type)\n",
        "room_type.shape=(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "5b813b8c",
      "metadata": {
        "id": "5b813b8c",
        "outputId": "b31d26c4-b920-4980-9ea6-940be9ea42bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(48895, 1)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "room_type.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d74eb3ae",
      "metadata": {
        "id": "d74eb3ae"
      },
      "outputs": [],
      "source": [
        "# Import the ordinal encoder object\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "# Create an ordinal encoder object\n",
        "en=OrdinalEncoder()\n",
        "\n",
        "# transform room type into an ordinal variable\n",
        "df['room_type']=en.fit_transform(room_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aacf31a",
      "metadata": {
        "id": "5aacf31a"
      },
      "source": [
        "## Convert neighbourhood into numeric data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g4QBRzPFpKtl",
      "metadata": {
        "id": "g4QBRzPFpKtl"
      },
      "source": [
        "Convert the 'neighbourhood' column into numerical data using one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "7358f73d",
      "metadata": {
        "id": "7358f73d"
      },
      "outputs": [],
      "source": [
        "neighbourhood=pd.DataFrame(df['neighbourhood'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca5d1f29",
      "metadata": {
        "id": "ca5d1f29",
        "outputId": "62943abe-6a81-4ce4-9064-3bbd6b9ddf60"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>neighbourhood</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kensington</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Midtown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Harlem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Clinton Hill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>East Harlem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48890</th>\n",
              "      <td>Bedford-Stuyvesant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48891</th>\n",
              "      <td>Bushwick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48892</th>\n",
              "      <td>Harlem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48893</th>\n",
              "      <td>Hell's Kitchen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48894</th>\n",
              "      <td>Hell's Kitchen</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48895 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            neighbourhood\n",
              "0              Kensington\n",
              "1                 Midtown\n",
              "2                  Harlem\n",
              "3            Clinton Hill\n",
              "4             East Harlem\n",
              "...                   ...\n",
              "48890  Bedford-Stuyvesant\n",
              "48891            Bushwick\n",
              "48892              Harlem\n",
              "48893      Hell's Kitchen\n",
              "48894      Hell's Kitchen\n",
              "\n",
              "[48895 rows x 1 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neighbourhood"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a763e1d1",
      "metadata": {},
      "source": [
        "`neighbourhood` is now a dataframe with only one column, also called neighbourhood. The column contains 'strings', basically encoding each neighbourhood with an English word. We want to encode the neighbourhood information in a numerical format, where each neighbourhood is a unique vector. We use the technique known as 'OneHotEncoder' that we have briefly seen in class. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d38bc5db",
      "metadata": {
        "id": "d38bc5db",
        "outputId": "54c9c27b-ec12-4ae8-ac40-99bc923070a4"
      },
      "outputs": [],
      "source": [
        "encoder=OneHotEncoder(sparse_output=True)\n",
        "k=encoder.fit_transform(neighbourhood)\n",
        "k"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c707690",
      "metadata": {},
      "source": [
        "### ✏️ Your turn \n",
        "> Based on your understanding of one hot encoding:\n",
        "> 1. Does the array contains only zeros? \n",
        "> 2. What is the sum of each row of numbers?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90d6a358",
      "metadata": {
        "id": "90d6a358",
        "outputId": "0ee35cdf-8af1-4917-b7b6-233391844508"
      },
      "outputs": [],
      "source": [
        "# print all neighbourhoods\n",
        "encoder.categories_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d415fa41",
      "metadata": {},
      "source": [
        "Let's create a dataframe with each category (neighbourhood) in a separate column and the one hot encoding vectors as separate rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c9c7875",
      "metadata": {
        "id": "0c9c7875"
      },
      "outputs": [],
      "source": [
        "p=pd.DataFrame(k,columns=encoder.categories_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83199921",
      "metadata": {
        "id": "83199921"
      },
      "outputs": [],
      "source": [
        "new_df=pd.concat([df,p],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c53c634a",
      "metadata": {
        "id": "c53c634a",
        "outputId": "a0e8713b-6db3-44c6-f78d-720f7cf2b57e"
      },
      "outputs": [],
      "source": [
        "new_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5cc593f",
      "metadata": {
        "id": "d5cc593f"
      },
      "source": [
        "## Convert neighbourhood_group into numeric data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E807ZCRPpPpM",
      "metadata": {
        "id": "E807ZCRPpPpM"
      },
      "source": [
        "Convert the 'neighbourhood_group' column into numerical data using one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77ef6c86",
      "metadata": {
        "id": "77ef6c86",
        "outputId": "0f680d8f-12f1-4339-fa70-3dfee60789b2"
      },
      "outputs": [],
      "source": [
        "df['neighbourhood_group'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6af9a38d",
      "metadata": {
        "id": "6af9a38d"
      },
      "outputs": [],
      "source": [
        "neighbourhood_grp=pd.DataFrame(df['neighbourhood_group'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec1083b2",
      "metadata": {},
      "source": [
        "### ✏️ Your turn \n",
        "> 1. use the one hot encoder to encode `neighbourhood_grp` and assign the result to a variable called `k`\n",
        "> 2. Use .categories_ to show the categories encoded\n",
        "> 3. Create a dataframe p using k as the values and categories as column names\n",
        "> 4. Concatenate new_df and p along the column axis, using `pd.concat`, and assign this new dataframe to `new_df`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "f24df0b4",
      "metadata": {
        "id": "f24df0b4"
      },
      "outputs": [],
      "source": [
        "# 1. use the one hot encoder to encode `neighbourhood_grp` and assign the result to a variable called `k`\n",
        "k = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "8fe6d84e",
      "metadata": {
        "id": "8fe6d84e",
        "outputId": "6062565d-5a40-4996-af31-a0fa7bd7eaba"
      },
      "outputs": [],
      "source": [
        "# 2. Use .categories_ to show the categories encoded\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "9c77c9f4",
      "metadata": {
        "id": "9c77c9f4"
      },
      "outputs": [],
      "source": [
        "# 3. Create a dataframe p using k as the values and categories as column names\n",
        "p = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "282bb1d7",
      "metadata": {
        "id": "282bb1d7"
      },
      "outputs": [],
      "source": [
        "# 4. Concatenate new_df and p along the column axis, using `pd.concat`, and assign this new dataframe to `new_df`\n",
        "new_df=..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02ce601a",
      "metadata": {
        "id": "02ce601a",
        "outputId": "12aa2b9b-2b6a-4759-80db-a70c2f75c1e0"
      },
      "outputs": [],
      "source": [
        "# Display new_df\n",
        "new_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IeFYHk64pT_2",
      "metadata": {
        "id": "IeFYHk64pT_2"
      },
      "source": [
        "Finally, let's drop the original categorical columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b9f6a1",
      "metadata": {
        "id": "51b9f6a1"
      },
      "outputs": [],
      "source": [
        "new_df.drop(l,axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "085dc1a8",
      "metadata": {
        "id": "085dc1a8",
        "outputId": "98476955-c485-4cb6-f185-03ae069d2d97"
      },
      "outputs": [],
      "source": [
        "new_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
